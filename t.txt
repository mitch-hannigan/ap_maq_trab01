dataset original

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 3810 entries, 0 to 3809
Data columns (total 8 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   Area               3810 non-null   float64
 1   Perimeter          3810 non-null   float64
 2   Major_Axis_Length  3810 non-null   float64
 3   Minor_Axis_Length  3810 non-null   float64
 4   Eccentricity       3810 non-null   float64
 5   Convex_Area        3810 non-null   float64
 6   Extent             3810 non-null   float64
 7   Class              3810 non-null   float64
dtypes: float64(8)
memory usage: 238.3 KB
iteração  1
validação, a acurácia do nayve_bays foi de  91.17647058823529 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  5 
peso =  uniform 
 acurácia =  88.97058823529412 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  2 
 acurácia =  93.27731092436974 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  gini 
max_depth =  4 
min_samples_leaf = 2 
min_samples_split = 7 
 acurácia =  92.5420168067227 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  500 
neurons (3 camadas) =  12 
ativação = relu 
taxa de aprendizagem = invscaling 
 acurácia =  86.5546218487395 %

resultado das execuções no conjunto de testes
O naive bayes obteve 90.34627492130114 % de acurácia nesta iteração.
O KNN obteve 87.09338929695699 % de acurácia nesta iteração.
O SVM obteve 93.1794333683106 % de acurácia nesta iteração.
A árvore de decisão obteve 92.86463798530956 % de acurácia nesta iteração.
O MLP obteve 85.41448058761804 % de acurácia nesta iteração.
A regra da soma obteve 91.71038824763903 % de acurácia nesta iteração.
O voto majoritário obteve 91.9202518363064 % de acurácia nesta iteração.
O método de borda count obteve 92.02518363064009 % de acurácia nesta iteração.
iteração  2
validação, a acurácia do nayve_bays foi de  90.02100840336135 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  14 
peso =  distance 
 acurácia =  88.02521008403362 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  3 
 acurácia =  92.22689075630252 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  entropy 
max_depth =  5 
min_samples_leaf = 4 
min_samples_split = 8 
 acurácia =  92.5420168067227 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  1000 
neurons (3 camadas) =  6 
ativação = relu 
taxa de aprendizagem = constant 
 acurácia =  85.60924369747899 %

resultado das execuções no conjunto de testes
O naive bayes obteve 91.81532004197271 % de acurácia nesta iteração.
O KNN obteve 88.66736621196223 % de acurácia nesta iteração.
O SVM obteve 92.65477439664218 % de acurácia nesta iteração.
A árvore de decisão obteve 92.02518363064009 % de acurácia nesta iteração.
O MLP obteve 85.93913955928646 % de acurácia nesta iteração.
A regra da soma obteve 92.02518363064009 % de acurácia nesta iteração.
O voto majoritário obteve 91.2906610703043 % de acurácia nesta iteração.
O método de borda count obteve 91.39559286463799 % de acurácia nesta iteração.
iteração  3
validação, a acurácia do nayve_bays foi de  91.7016806722689 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  45 
peso =  uniform 
 acurácia =  89.39075630252101 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  2 
 acurácia =  93.80252100840336 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  gini 
max_depth =  4 
min_samples_leaf = 3 
min_samples_split = 10 
 acurácia =  93.4873949579832 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  500 
neurons (3 camadas) =  12 
ativação = relu 
taxa de aprendizagem = invscaling 
 acurácia =  89.39075630252101 %

resultado das execuções no conjunto de testes
O naive bayes obteve 91.08079748163694 % de acurácia nesta iteração.
O KNN obteve 88.1427072402938 % de acurácia nesta iteração.
O SVM obteve 91.50052465897167 % de acurácia nesta iteração.
A árvore de decisão obteve 91.50052465897167 % de acurácia nesta iteração.
O MLP obteve 87.5131164742917 % de acurácia nesta iteração.
A regra da soma obteve 91.08079748163694 % de acurácia nesta iteração.
O voto majoritário obteve 91.08079748163694 % de acurácia nesta iteração.
O método de borda count obteve 91.08079748163694 % de acurácia nesta iteração.
iteração  4
validação, a acurácia do nayve_bays foi de  91.91176470588235 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  11 
peso =  distance 
 acurácia =  89.49579831932773 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  1 
 acurácia =  93.0672268907563 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  entropy 
max_depth =  3 
min_samples_leaf = 1 
min_samples_split = 2 
 acurácia =  92.64705882352942 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  1000 
neurons (3 camadas) =  6 
ativação = identity 
taxa de aprendizagem = invscaling 
 acurácia =  90.75630252100841 %

resultado das execuções no conjunto de testes
O naive bayes obteve 91.50052465897167 % de acurácia nesta iteração.
O KNN obteve 89.50682056663169 % de acurácia nesta iteração.
O SVM obteve 92.96956977964324 % de acurácia nesta iteração.
A árvore de decisão obteve 92.75970619097586 % de acurácia nesta iteração.
O MLP obteve 90.97586568730324 % de acurácia nesta iteração.
A regra da soma obteve 92.75970619097586 % de acurácia nesta iteração.
O voto majoritário obteve 92.96956977964324 % de acurácia nesta iteração.
O método de borda count obteve 92.96956977964324 % de acurácia nesta iteração.
iteração  5
validação, a acurácia do nayve_bays foi de  90.65126050420169 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  23 
peso =  distance 
 acurácia =  87.71008403361344 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  1 
 acurácia =  93.17226890756302 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  entropy 
max_depth =  3 
min_samples_leaf = 5 
min_samples_split = 10 
 acurácia =  92.75210084033614 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  1000 
neurons (3 camadas) =  12 
ativação = relu 
taxa de aprendizagem = adaptive 
 acurácia =  89.91596638655463 %

resultado das execuções no conjunto de testes
O naive bayes obteve 91.60545645330535 % de acurácia nesta iteração.
O KNN obteve 88.66736621196223 % de acurácia nesta iteração.
O SVM obteve 92.96956977964324 % de acurácia nesta iteração.
A árvore de decisão obteve 91.08079748163694 % de acurácia nesta iteração.
O MLP obteve 90.7660020986359 % de acurácia nesta iteração.
A regra da soma obteve 91.81532004197271 % de acurácia nesta iteração.
O voto majoritário obteve 92.33997901364114 % de acurácia nesta iteração.
O método de borda count obteve 92.33997901364114 % de acurácia nesta iteração.
iteração  6
validação, a acurácia do nayve_bays foi de  91.7016806722689 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  13 
peso =  uniform 
 acurácia =  89.49579831932773 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  2 
 acurácia =  94.11764705882352 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  gini 
max_depth =  4 
min_samples_leaf = 1 
min_samples_split = 2 
 acurácia =  93.59243697478992 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  1000 
neurons (3 camadas) =  6 
ativação = relu 
taxa de aprendizagem = invscaling 
 acurácia =  90.02100840336135 %

resultado das execuções no conjunto de testes
O naive bayes obteve 90.55613850996852 % de acurácia nesta iteração.
O KNN obteve 87.82791185729276 % de acurácia nesta iteração.
O SVM obteve 92.65477439664218 % de acurácia nesta iteração.
A árvore de decisão obteve 91.81532004197271 % de acurácia nesta iteração.
O MLP obteve 88.56243441762854 % de acurácia nesta iteração.
A regra da soma obteve 91.2906610703043 % de acurácia nesta iteração.
O voto majoritário obteve 91.50052465897167 % de acurácia nesta iteração.
O método de borda count obteve 91.50052465897167 % de acurácia nesta iteração.
iteração  7
validação, a acurácia do nayve_bays foi de  92.22689075630252 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  7 
peso =  distance 
 acurácia =  89.91596638655463 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  1 
 acurácia =  94.22268907563026 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  gini 
max_depth =  3 
min_samples_leaf = 1 
min_samples_split = 2 
 acurácia =  94.0126050420168 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  300 
neurons (3 camadas) =  6 
ativação = relu 
taxa de aprendizagem = invscaling 
 acurácia =  91.28151260504201 %

resultado das execuções no conjunto de testes
O naive bayes obteve 90.6610703043022 % de acurácia nesta iteração.
O KNN obteve 88.03777544596014 % de acurácia nesta iteração.
O SVM obteve 92.96956977964324 % de acurácia nesta iteração.
A árvore de decisão obteve 92.5498426023085 % de acurácia nesta iteração.
O MLP obteve 90.87093389296957 % de acurácia nesta iteração.
A regra da soma obteve 91.50052465897167 % de acurácia nesta iteração.
O voto majoritário obteve 92.13011542497377 % de acurácia nesta iteração.
O método de borda count obteve 92.13011542497377 % de acurácia nesta iteração.
iteração  8
validação, a acurácia do nayve_bays foi de  90.75630252100841 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  6 
peso =  distance 
 acurácia =  88.8655462184874 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  3 
 acurácia =  93.0672268907563 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  gini 
max_depth =  4 
min_samples_leaf = 1 
min_samples_split = 3 
 acurácia =  92.96218487394958 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  150 
neurons (3 camadas) =  12 
ativação = relu 
taxa de aprendizagem = constant 
 acurácia =  80.88235294117648 %

resultado das execuções no conjunto de testes
O naive bayes obteve 90.6610703043022 % de acurácia nesta iteração.
O KNN obteve 86.56873032528857 % de acurácia nesta iteração.
O SVM obteve 91.2906610703043 % de acurácia nesta iteração.
A árvore de decisão obteve 91.2906610703043 % de acurácia nesta iteração.
O MLP obteve 80.06295907660021 % de acurácia nesta iteração.
A regra da soma obteve 90.45120671563484 % de acurácia nesta iteração.
O voto majoritário obteve 90.0314795383001 % de acurácia nesta iteração.
O método de borda count obteve 89.92654774396642 % de acurácia nesta iteração.
iteração  9
validação, a acurácia do nayve_bays foi de  92.01680672268907 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  29 
peso =  distance 
 acurácia =  89.07563025210085 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  2 
 acurácia =  93.80252100840336 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  entropy 
max_depth =  5 
min_samples_leaf = 2 
min_samples_split = 4 
 acurácia =  93.27731092436974 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  500 
neurons (3 camadas) =  6 
ativação = relu 
taxa de aprendizagem = constant 
 acurácia =  86.65966386554622 %

resultado das execuções no conjunto de testes
O naive bayes obteve 89.92654774396642 % de acurácia nesta iteração.
O KNN obteve 88.1427072402938 % de acurácia nesta iteração.
O SVM obteve 91.81532004197271 % de acurácia nesta iteração.
A árvore de decisão obteve 90.97586568730324 % de acurácia nesta iteração.
O MLP obteve 84.15529905561385 % de acurácia nesta iteração.
A regra da soma obteve 90.7660020986359 % de acurácia nesta iteração.
O voto majoritário obteve 91.60545645330535 % de acurácia nesta iteração.
O método de borda count obteve 91.50052465897167 % de acurácia nesta iteração.
iteração  10
validação, a acurácia do nayve_bays foi de  90.02100840336135 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  6 
peso =  distance 
 acurácia =  87.92016806722688 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  4 
 acurácia =  92.01680672268907 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  gini 
max_depth =  3 
min_samples_leaf = 1 
min_samples_split = 2 
 acurácia =  91.59663865546219 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  500 
neurons (3 camadas) =  6 
ativação = relu 
taxa de aprendizagem = constant 
 acurácia =  82.24789915966386 %

resultado das execuções no conjunto de testes
O naive bayes obteve 92.96956977964324 % de acurácia nesta iteração.
O KNN obteve 89.08709338929695 % de acurácia nesta iteração.
O SVM obteve 93.59916054564533 % de acurácia nesta iteração.
A árvore de decisão obteve 93.80902413431271 % de acurácia nesta iteração.
O MLP obteve 83.8405036726128 % de acurácia nesta iteração.
A regra da soma obteve 92.86463798530956 % de acurácia nesta iteração.
O voto majoritário obteve 93.28436516264428 % de acurácia nesta iteração.
O método de borda count obteve 93.1794333683106 % de acurácia nesta iteração.
iteração  11
validação, a acurácia do nayve_bays foi de  91.80672268907563 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  17 
peso =  distance 
 acurácia =  89.60084033613445 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  1 
 acurácia =  94.11764705882352 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  entropy 
max_depth =  3 
min_samples_leaf = 1 
min_samples_split = 2 
 acurácia =  93.59243697478992 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  150 
neurons (3 camadas) =  6 
ativação = relu 
taxa de aprendizagem = invscaling 
 acurácia =  83.19327731092437 %

resultado das execuções no conjunto de testes
O naive bayes obteve 90.6610703043022 % de acurácia nesta iteração.
O KNN obteve 86.46379853095489 % de acurácia nesta iteração.
O SVM obteve 92.02518363064009 % de acurácia nesta iteração.
A árvore de decisão obteve 91.9202518363064 % de acurácia nesta iteração.
O MLP obteve 81.32214060860441 % de acurácia nesta iteração.
A regra da soma obteve 91.08079748163694 % de acurácia nesta iteração.
O voto majoritário obteve 90.97586568730324 % de acurácia nesta iteração.
O método de borda count obteve 91.08079748163694 % de acurácia nesta iteração.
iteração  12
validação, a acurácia do nayve_bays foi de  89.60084033613445 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  47 
peso =  distance 
 acurácia =  88.34033613445378 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  1 
 acurácia =  91.7016806722689 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  gini 
max_depth =  4 
min_samples_leaf = 5 
min_samples_split = 14 
 acurácia =  91.28151260504201 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  1000 
neurons (3 camadas) =  6 
ativação = identity 
taxa de aprendizagem = invscaling 
 acurácia =  85.18907563025209 %

resultado das execuções no conjunto de testes
O naive bayes obteve 91.18572927597062 % de acurácia nesta iteração.
O KNN obteve 88.87722980062959 % de acurácia nesta iteração.
O SVM obteve 93.59916054564533 % de acurácia nesta iteração.
A árvore de decisão obteve 93.38929695697796 % de acurácia nesta iteração.
O MLP obteve 86.04407135362014 % de acurácia nesta iteração.
A regra da soma obteve 91.81532004197271 % de acurácia nesta iteração.
O voto majoritário obteve 92.13011542497377 % de acurácia nesta iteração.
O método de borda count obteve 92.13011542497377 % de acurácia nesta iteração.
iteração  13
validação, a acurácia do nayve_bays foi de  91.17647058823529 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  42 
peso =  distance 
 acurácia =  88.97058823529412 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  3 
 acurácia =  93.0672268907563 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  entropy 
max_depth =  4 
min_samples_leaf = 3 
min_samples_split = 6 
 acurácia =  92.5420168067227 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  150 
neurons (3 camadas) =  6 
ativação = relu 
taxa de aprendizagem = adaptive 
 acurácia =  87.18487394957984 %

resultado das execuções no conjunto de testes
O naive bayes obteve 91.71038824763903 % de acurácia nesta iteração.
O KNN obteve 87.93284365162644 % de acurácia nesta iteração.
O SVM obteve 92.65477439664218 % de acurácia nesta iteração.
A árvore de decisão obteve 92.65477439664218 % de acurácia nesta iteração.
O MLP obteve 85.93913955928646 % de acurácia nesta iteração.
A regra da soma obteve 92.13011542497377 % de acurácia nesta iteração.
O voto majoritário obteve 91.50052465897167 % de acurácia nesta iteração.
O método de borda count obteve 91.50052465897167 % de acurácia nesta iteração.
iteração  14
validação, a acurácia do nayve_bays foi de  90.75630252100841 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  5 
peso =  distance 
 acurácia =  89.18067226890757 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  4 
 acurácia =  92.33193277310924 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  entropy 
max_depth =  3 
min_samples_leaf = 2 
min_samples_split = 4 
 acurácia =  92.43697478991596 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  500 
neurons (3 camadas) =  6 
ativação = identity 
taxa de aprendizagem = constant 
 acurácia =  88.76050420168067 %

resultado das execuções no conjunto de testes
O naive bayes obteve 90.87093389296957 % de acurácia nesta iteração.
O KNN obteve 87.5131164742917 % de acurácia nesta iteração.
O SVM obteve 92.96956977964324 % de acurácia nesta iteração.
A árvore de decisão obteve 92.44491080797481 % de acurácia nesta iteração.
O MLP obteve 90.0314795383001 % de acurácia nesta iteração.
A regra da soma obteve 91.39559286463799 % de acurácia nesta iteração.
O voto majoritário obteve 92.02518363064009 % de acurácia nesta iteração.
O método de borda count obteve 92.02518363064009 % de acurácia nesta iteração.
iteração  15
validação, a acurácia do nayve_bays foi de  91.91176470588235 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  24 
peso =  distance 
 acurácia =  89.28571428571429 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  4 
 acurácia =  94.32773109243698 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  gini 
max_depth =  3 
min_samples_leaf = 1 
min_samples_split = 2 
 acurácia =  94.32773109243698 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  1000 
neurons (3 camadas) =  6 
ativação = relu 
taxa de aprendizagem = adaptive 
 acurácia =  84.66386554621849 %

resultado das execuções no conjunto de testes
O naive bayes obteve 89.82161594963274 % de acurácia nesta iteração.
O KNN obteve 86.67366211962224 % de acurácia nesta iteração.
O SVM obteve 92.23504721930745 % de acurácia nesta iteração.
A árvore de decisão obteve 91.81532004197271 % de acurácia nesta iteração.
O MLP obteve 82.5813221406086 % de acurácia nesta iteração.
A regra da soma obteve 90.6610703043022 % de acurácia nesta iteração.
O voto majoritário obteve 91.39559286463799 % de acurácia nesta iteração.
O método de borda count obteve 91.39559286463799 % de acurácia nesta iteração.
iteração  16
validação, a acurácia do nayve_bays foi de  90.44117647058823 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  11 
peso =  distance 
 acurácia =  88.23529411764706 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  3 
 acurácia =  93.27731092436974 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  entropy 
max_depth =  7 
min_samples_leaf = 5 
min_samples_split = 13 
 acurácia =  92.5420168067227 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  150 
neurons (3 camadas) =  12 
ativação = relu 
taxa de aprendizagem = constant 
 acurácia =  80.35714285714286 %

resultado das execuções no conjunto de testes
O naive bayes obteve 91.60545645330535 % de acurácia nesta iteração.
O KNN obteve 88.98216159496327 % de acurácia nesta iteração.
O SVM obteve 93.59916054564533 % de acurácia nesta iteração.
A árvore de decisão obteve 92.13011542497377 % de acurácia nesta iteração.
O MLP obteve 80.79748163693598 % de acurácia nesta iteração.
A regra da soma obteve 92.5498426023085 % de acurácia nesta iteração.
O voto majoritário obteve 92.23504721930745 % de acurácia nesta iteração.
O método de borda count obteve 92.13011542497377 % de acurácia nesta iteração.
iteração  17
validação, a acurácia do nayve_bays foi de  90.54621848739495 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  23 
peso =  uniform 
 acurácia =  88.34033613445378 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  1 
 acurácia =  92.96218487394958 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  gini 
max_depth =  4 
min_samples_leaf = 5 
min_samples_split = 10 
 acurácia =  92.5420168067227 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  300 
neurons (3 camadas) =  6 
ativação = relu 
taxa de aprendizagem = adaptive 
 acurácia =  89.81092436974791 %

resultado das execuções no conjunto de testes
O naive bayes obteve 90.97586568730324 % de acurácia nesta iteração.
O KNN obteve 87.61804826862539 % de acurácia nesta iteração.
O SVM obteve 93.38929695697796 % de acurácia nesta iteração.
A árvore de decisão obteve 93.1794333683106 % de acurácia nesta iteração.
O MLP obteve 90.24134312696746 % de acurácia nesta iteração.
A regra da soma obteve 92.33997901364114 % de acurácia nesta iteração.
O voto majoritário obteve 92.13011542497377 % de acurácia nesta iteração.
O método de borda count obteve 92.02518363064009 % de acurácia nesta iteração.
iteração  18
validação, a acurácia do nayve_bays foi de  90.96638655462185 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  11 
peso =  uniform 
 acurácia =  88.97058823529412 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  3 
 acurácia =  92.85714285714286 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  gini 
max_depth =  5 
min_samples_leaf = 4 
min_samples_split = 9 
 acurácia =  93.0672268907563 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  150 
neurons (3 camadas) =  6 
ativação = identity 
taxa de aprendizagem = constant 
 acurácia =  85.60924369747899 %

resultado das execuções no conjunto de testes
O naive bayes obteve 91.18572927597062 % de acurácia nesta iteração.
O KNN obteve 88.45750262329486 % de acurácia nesta iteração.
O SVM obteve 93.28436516264428 % de acurácia nesta iteração.
A árvore de decisão obteve 92.44491080797481 % de acurácia nesta iteração.
O MLP obteve 86.77859391395593 % de acurácia nesta iteração.
A regra da soma obteve 92.02518363064009 % de acurácia nesta iteração.
O voto majoritário obteve 91.71038824763903 % de acurácia nesta iteração.
O método de borda count obteve 91.71038824763903 % de acurácia nesta iteração.
iteração  19
validação, a acurácia do nayve_bays foi de  92.12184873949579 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  12 
peso =  uniform 
 acurácia =  88.8655462184874 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  1 
 acurácia =  93.4873949579832 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  entropy 
max_depth =  4 
min_samples_leaf = 1 
min_samples_split = 4 
 acurácia =  92.43697478991596 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  300 
neurons (3 camadas) =  6 
ativação = relu 
taxa de aprendizagem = adaptive 
 acurácia =  88.02521008403362 %

resultado das execuções no conjunto de testes
O naive bayes obteve 91.39559286463799 % de acurácia nesta iteração.
O KNN obteve 88.35257082896118 % de acurácia nesta iteração.
O SVM obteve 93.70409233997901 % de acurácia nesta iteração.
A árvore de decisão obteve 92.23504721930745 % de acurácia nesta iteração.
O MLP obteve 87.93284365162644 % de acurácia nesta iteração.
A regra da soma obteve 91.81532004197271 % de acurácia nesta iteração.
O voto majoritário obteve 91.39559286463799 % de acurácia nesta iteração.
O método de borda count obteve 91.39559286463799 % de acurácia nesta iteração.
iteração  20
validação, a acurácia do nayve_bays foi de  92.43697478991596 %
validação, os melhores parâmetros para o knn nessa iteração são:
K =  43 
peso =  distance 
 acurácia =  89.70588235294117 %

validação, os melhores parâmetros para o SVM nessa iteração são:
Kernel =  linear 
C =  2 
 acurácia =  93.80252100840336 %

validação, os melhores parâmetros para a árvore de decisão nessa iteração são:
criterion =  entropy 
max_depth =  4 
min_samples_leaf = 2 
min_samples_split = 4 
 acurácia =  93.4873949579832 %

validação, os melhores parâmetros para o MLP nesta iteração são:
iterações =  150 
neurons (3 camadas) =  6 
ativação = identity 
taxa de aprendizagem = adaptive 
 acurácia =  86.65966386554622 %

resultado das execuções no conjunto de testes
O naive bayes obteve 91.60545645330535 % de acurácia nesta iteração.
O KNN obteve 89.92654774396642 % de acurácia nesta iteração.
O SVM obteve 92.96956977964324 % de acurácia nesta iteração.
A árvore de decisão obteve 92.75970619097586 % de acurácia nesta iteração.
O MLP obteve 87.30325288562435 % de acurácia nesta iteração.
A regra da soma obteve 91.71038824763903 % de acurácia nesta iteração.
O voto majoritário obteve 91.81532004197271 % de acurácia nesta iteração.
O método de borda count obteve 91.81532004197271 % de acurácia nesta iteração.
